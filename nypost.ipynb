{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the requests library and BeautifulSoup, both standard for any scraping-related tasks. Since NYPost blocks Python requests we can use the fake_useragent library to bypass this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testurl = requests.get(\"https://nypost.com/search/congestion+pricing/\", headers = headers)\n",
    "souptest = BeautifulSoup(testurl.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nypost_scraper(keyword, max_pages):\n",
    "    base_url = \"https://nypost.com/search/\"\n",
    "    results = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"{base_url}{keyword}/page/{page}/\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code!=200:\n",
    "            print(f\"Failed to fetch page {page}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        story_texts = soup.find_all('div', class_='story__text')\n",
    "        for story in story_texts:\n",
    "            # Extract title and link\n",
    "            headline = story.find('h3', class_='story__headline')\n",
    "            if headline:\n",
    "                title_tag = headline.find('a')\n",
    "                title = title_tag.text.strip() if title_tag else \"No title\"\n",
    "                link = title_tag['href'] if title_tag and title_tag.has_attr('href') else \"No link\"\n",
    "\n",
    "            # Extract author and date\n",
    "            meta = story.find('span', class_='meta meta--byline')\n",
    "            if meta:\n",
    "                # Split the content on the \"|\" character for date separation\n",
    "                meta_parts = meta.text.strip().split('|')\n",
    "                author = meta_parts[0].replace(\"By\", \"\").strip() if len(meta_parts) > 0 else \"No author\"\n",
    "                date = meta_parts[1].strip() if len(meta_parts) > 1 else \"No date\"\n",
    "            else:\n",
    "                author = \"No author\"\n",
    "                date = \"No date\"\n",
    "            # Extract excerpt\n",
    "            excerpt_tag = story.find('p', class_='story__excerpt')\n",
    "            excerpt = excerpt_tag.text.strip() if excerpt_tag else \"No excerpt\"\n",
    "\n",
    "            # Append information to the list\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'author': author,\n",
    "                'date': date,\n",
    "                'excerpt': excerpt\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nypost_scraper(\"congestion+pricing\",max_pages=20)\n",
    "df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>name_date</th>\n",
       "      <th>time</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oregon effort to shift border, join conservati...</td>\n",
       "      <td>https://nypost.com/2025/02/17/us-news/eastern-...</td>\n",
       "      <td>Charles Creitz, Fox News \\t\\t\\t\\tFebruary 17, ...</td>\n",
       "      <td>12:15pm</td>\n",
       "      <td>\"This movement has always been about the peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luxury skincare sale! One of our favorite bran...</td>\n",
       "      <td>https://nypost.com/2025/02/17/shopping/shop-th...</td>\n",
       "      <td>Victoria Giardina \\t\\t\\t\\tFebruary 17, 2025</td>\n",
       "      <td>7:00am</td>\n",
       "      <td>Luxury, within reach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY's Gov. Hochul chimes in on E-ZPass texting ...</td>\n",
       "      <td>https://nypost.com/2025/02/16/us-news/hochul-c...</td>\n",
       "      <td>Carl Campanile and Jorge Fitz-Gibbon \\t\\t\\t\\tF...</td>\n",
       "      <td>5:22pm</td>\n",
       "      <td>Gov. Kathy Hochul chimed in and issued a warni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asian group tired of far-left Dems urges Andre...</td>\n",
       "      <td>https://nypost.com/2025/02/16/us-news/andrew-c...</td>\n",
       "      <td>Carl Campanile \\t\\t\\t\\tFebruary 16, 2025</td>\n",
       "      <td>4:03pm</td>\n",
       "      <td>The Asian Wave Alliance advocates for merit-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homes prices and new developments are booming ...</td>\n",
       "      <td>https://nypost.com/2025/02/14/real-estate/home...</td>\n",
       "      <td>David Christopher Kaufman \\t\\t\\t\\tFebruary 14,...</td>\n",
       "      <td>5:40pm</td>\n",
       "      <td>The right track: It’s full steam ahead, as lux...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Oregon effort to shift border, join conservati...   \n",
       "1  Luxury skincare sale! One of our favorite bran...   \n",
       "2  NY's Gov. Hochul chimes in on E-ZPass texting ...   \n",
       "3  Asian group tired of far-left Dems urges Andre...   \n",
       "4  Homes prices and new developments are booming ...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://nypost.com/2025/02/17/us-news/eastern-...   \n",
       "1  https://nypost.com/2025/02/17/shopping/shop-th...   \n",
       "2  https://nypost.com/2025/02/16/us-news/hochul-c...   \n",
       "3  https://nypost.com/2025/02/16/us-news/andrew-c...   \n",
       "4  https://nypost.com/2025/02/14/real-estate/home...   \n",
       "\n",
       "                                           name_date     time  \\\n",
       "0  Charles Creitz, Fox News \\t\\t\\t\\tFebruary 17, ...  12:15pm   \n",
       "1        Victoria Giardina \\t\\t\\t\\tFebruary 17, 2025   7:00am   \n",
       "2  Carl Campanile and Jorge Fitz-Gibbon \\t\\t\\t\\tF...   5:22pm   \n",
       "3           Carl Campanile \\t\\t\\t\\tFebruary 16, 2025   4:03pm   \n",
       "4  David Christopher Kaufman \\t\\t\\t\\tFebruary 14,...   5:40pm   \n",
       "\n",
       "                                             excerpt  \n",
       "0  \"This movement has always been about the peopl...  \n",
       "1                              Luxury, within reach.  \n",
       "2  Gov. Kathy Hochul chimed in and issued a warni...  \n",
       "3  The Asian Wave Alliance advocates for merit-ba...  \n",
       "4  The right track: It’s full steam ahead, as lux...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'date' : 'time', 'author' : 'name_date'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['author', 'date']] = df['name_date'].str.split(r'\\t+', expand=True)\n",
    "df.drop(columns=['name_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('nyp_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "- Figure out a way to remove ads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
