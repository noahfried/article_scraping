{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the requests library and BeautifulSoup, both standard for any scraping-related tasks. Since NYPost blocks Python requests we can use the fake_useragent library to bypass this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise random useragent headers for URL requests to get around NYPost Python blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify keyword (search term) and desired number of search result pages for scraping. Use BeautifulSoup to obtain html, then select for divs with 'story__text' class and extract headline, meta information (author and date), and excerpt (byline). Store this in results list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nypost_scraper(keyword, max_pages):\n",
    "    base_url = \"https://nypost.com/search/\"\n",
    "    results = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"{base_url}{keyword}/page/{page}/\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code!=200:\n",
    "            print(f\"Failed to fetch page {page}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        story_texts = soup.find_all('div', class_='story__text')\n",
    "        for story in story_texts:\n",
    "            # Extract title and link\n",
    "            headline = story.find('h3', class_='story__headline')\n",
    "            if headline:\n",
    "                title_tag = headline.find('a')\n",
    "                title = title_tag.text.strip() if title_tag else \"No title\"\n",
    "                link = title_tag['href'] if title_tag and title_tag.has_attr('href') else \"No link\"\n",
    "\n",
    "            # Extract author and date\n",
    "            meta = story.find('span', class_='meta meta--byline')\n",
    "            if meta:\n",
    "                # Split the content on the \"|\" character for date separation\n",
    "                meta_parts = meta.text.strip().split('|')\n",
    "                author = meta_parts[0].replace(\"By\", \"\").strip() if len(meta_parts) > 0 else \"No author\"\n",
    "                date = meta_parts[1].strip() if len(meta_parts) > 1 else \"No date\"\n",
    "            else:\n",
    "                author = \"No author\"\n",
    "                date = \"No date\"\n",
    "            # Extract excerpt\n",
    "            excerpt_tag = story.find('p', class_='story__excerpt')\n",
    "            excerpt = excerpt_tag.text.strip() if excerpt_tag else \"No excerpt\"\n",
    "\n",
    "            # Append information to the list\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'author': author,\n",
    "                'date': date,\n",
    "                'excerpt': excerpt\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call function and use pandas to fix formatting issues with author/date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nypost_scraper(\"congestion+pricing\",max_pages=20)\n",
    "df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>name_date</th>\n",
       "      <th>time</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTA sues to keep congestion pricing in place a...</td>\n",
       "      <td>https://nypost.com/2025/02/19/us-news/mta-sues...</td>\n",
       "      <td>Carl Campanile, Ben Kochman and Chris Nesi \\t\\...</td>\n",
       "      <td>1:54pm</td>\n",
       "      <td>MTA Chair and CEO Janno Lieber praised the tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC congestion pricing axed as Trump's DOT pul...</td>\n",
       "      <td>https://nypost.com/2025/02/19/us-news/nyc-cong...</td>\n",
       "      <td>Jon Levine and Chris Nesi \\t\\t\\t\\tFebruary 19,...</td>\n",
       "      <td>12:02pm</td>\n",
       "      <td>Congestion pricing, we hardly knew ye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gov. Hochul's cowardice is on full display as ...</td>\n",
       "      <td>https://nypost.com/2025/02/18/opinion/michael-...</td>\n",
       "      <td>Michael Goodwin \\t\\t\\t\\tFebruary 18, 2025</td>\n",
       "      <td>10:36pm</td>\n",
       "      <td>Gov. Hochul falls short on governing skills, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oregon effort to shift border, join conservati...</td>\n",
       "      <td>https://nypost.com/2025/02/17/us-news/eastern-...</td>\n",
       "      <td>Charles Creitz, Fox News \\t\\t\\t\\tFebruary 17, ...</td>\n",
       "      <td>12:15pm</td>\n",
       "      <td>\"This movement has always been about the peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luxury skincare sale! One of our favorite bran...</td>\n",
       "      <td>https://nypost.com/2025/02/17/shopping/shop-th...</td>\n",
       "      <td>Victoria Giardina \\t\\t\\t\\tFebruary 17, 2025</td>\n",
       "      <td>7:00am</td>\n",
       "      <td>Luxury, within reach.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  MTA sues to keep congestion pricing in place a...   \n",
       "1  NYC congestion pricing axed as Trump's DOT pul...   \n",
       "2  Gov. Hochul's cowardice is on full display as ...   \n",
       "3  Oregon effort to shift border, join conservati...   \n",
       "4  Luxury skincare sale! One of our favorite bran...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://nypost.com/2025/02/19/us-news/mta-sues...   \n",
       "1  https://nypost.com/2025/02/19/us-news/nyc-cong...   \n",
       "2  https://nypost.com/2025/02/18/opinion/michael-...   \n",
       "3  https://nypost.com/2025/02/17/us-news/eastern-...   \n",
       "4  https://nypost.com/2025/02/17/shopping/shop-th...   \n",
       "\n",
       "                                           name_date     time  \\\n",
       "0  Carl Campanile, Ben Kochman and Chris Nesi \\t\\...   1:54pm   \n",
       "1  Jon Levine and Chris Nesi \\t\\t\\t\\tFebruary 19,...  12:02pm   \n",
       "2          Michael Goodwin \\t\\t\\t\\tFebruary 18, 2025  10:36pm   \n",
       "3  Charles Creitz, Fox News \\t\\t\\t\\tFebruary 17, ...  12:15pm   \n",
       "4        Victoria Giardina \\t\\t\\t\\tFebruary 17, 2025   7:00am   \n",
       "\n",
       "                                             excerpt  \n",
       "0  MTA Chair and CEO Janno Lieber praised the tol...  \n",
       "1             Congestion pricing, we hardly knew ye.  \n",
       "2  Gov. Hochul falls short on governing skills, b...  \n",
       "3  \"This movement has always been about the peopl...  \n",
       "4                              Luxury, within reach.  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'date' : 'time', 'author' : 'name_date'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['author', 'date']] = df['name_date'].str.split(r'\\t+', expand=True)\n",
    "df.drop(columns=['name_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('nyp_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- Figure out a way to remove ads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
